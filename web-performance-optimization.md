# 《Web性能权威指南》

> 合格的开发者知道怎么做，而优秀的开发者知道为什么那么做。

> 本书中，作者解释了网络编程中的很多为什么：为什么延迟是性能瓶颈？为什么TCP并不总是最优传输机制，而UDP有时候反而是更好的选择？为什么崇勇连接是关键性的优化策略？然后又更进一步的给出了网络性能的具体建议。想要降低延迟？在靠近客户端的服务器上完成会话。想要提高连接重用率？保持连接持久化。除此之外，本书还讲解了协议和浏览器的最新进展。讲了HTTP 2.0的诸多有点，回顾了XHR及其催生的CORS(Cross-Origin Resource Sharing, 跨域资源共享)的局限性，还有SSE(Server-Sent Events, 服务器发送事件)、WebSockets 和 WebRTC。

## 第一部分  网络技术概览

### 第一章   延迟和带宽

#### 速度是关键

1. 在这个节奏越来越快、联系越来越紧密的世界，追求速度不仅仅是一种心理上的需要，更是一种由现实事例驱动的用户需求。很多在线公司的业绩已经证实：
 - 网站越快，用户的黏性越高；
 - 网站越快，用户忠诚度越高；
 - 网站越快，用户转换率越高；
对所有网络通信都有决定性影响的两个方面：延迟和带宽
+ 延迟
  分组从信息源发送到目的地所需的时间
+ 带宽
  逻辑或物理通信路径最大的吞吐量

![延迟和带宽](/img/web-performance-optimization/speed.jpg)
  
2. 延迟的构成
    延迟是消息(message)或分组(packet)从起点到终点经历的时间。路由器这个负责在客户端和服务器之间转发消息的设备，会牵涉哪些影响延迟的因素有
    - 传播延迟
        消息从发送端到接收端需要的时间，是信号转播距离和速度的函数
    - 传输延迟
        把消息中的所有比特转移到链路中需要的时间，是消息长度和链路速率的函数
    - 处理延迟
        处理分组首部、检查位错误及确定分组目标所需的时间
    - 排队延迟
        到来的分组排队等待处理的时间
    以上延迟的时间总和，就是客户端到服务器的总延迟时间。传播时间取决于距离和信号通过的媒介，另外传播速度通常不超过光速。而传输延迟由传输链路的速率决定，与客户端到服务器的距离无关。接着，分组到达路由器。路由器必须检测分组的首部，以确定出站路由，并且还可能对数据进行检查，这些都要花时间。由于这些检查通常由硬件完成，因此相应的延迟一般非常短，但再短也还是存在。最后，如果分组到达的速度超过了路由器的处理能力，那么分组就要在入站缓冲区排队。数据在缓冲区排队等待的时间就是排队延迟。
    每个分组在通过网络时都会遇到这样或那样的延迟。发送端与接收端的距离越远，传播时间就越长。一路上经过的路由器越多，每个分组的处理和传输延迟就越多。最后，网络流量越拥挤，分组在入站缓冲区中被延迟的可能性就越大。

3. 光速与传播延迟
    要想给用户最佳的体验，而且保证他们会全神贯注于手边的任务，我们的应用必须在几百ms之内响应。这几乎没有给我们——特别是网络，留出多少出错的余地。若要成功，必须认真对待网络延迟，在每个开发阶段都为它设立明确的标准。
    CDN(Content Delivery Network, 内容分发网络)服务的用途很多，但是重要的就是通过把内容部署在全球各地，让用户从最近的服务器加载内容，大幅降低传播分组的时间。

4. 延迟的最后一公里
    大多数网站性能的瓶颈都是延迟，而不是带宽！

5. 网络核心的带宽
    通过波分复用(WDM,Wavelength-Division Multiplexing)技术，光纤可以同时传输很多不同波长（通道）的光，因而具有明显的带宽优势。一条光纤连接的总带宽，等于每个信道的数据传输速率乘以可复用的信道数。

6. 网络边缘的带宽
    用户可用带宽取决于客户端与目标服务器间最低容量连接。由于请求密集、硬件故障、网络攻击，以及其他很多原因，网络的某个中间节点随时都有可能发生拥塞。吞吐量和延迟波动大是因特网固有的特点。

7. 目标：高带宽和低延迟
    目前的视频流量已经占到全部因特网流量的一半以上，人们对高带宽的需求迅速增长。我们可以使用在光纤链路中部署更多光纤、在拥塞的路由之间铺设更多线路甚至是改进WDM技术等方法来提高容量，以便让现有连接能够传输更多数据。但是减少延迟相对来说就要困难得多，通过提升光纤线路的质量来让光信号传输的速度更接近光速。比如采用折射率更低的材料、速度更快的路由器和中继器等。


### 第二章   TCP的构成

因特网有两个核心协议：IP和TCP。IP，即Internet Protocol(因特网协议)，负责联网主机之间的路由选择和寻址；TCP，即Transmission Control Protocol(传输控制协议)，负责在不可靠的传输信道之上提供可靠的抽象层。TCP/IP也常被称为“因特网协议套件”(Internet Protocol Suite).

TCP负责在不可靠的传输信道之上提供可靠的抽象层，向应用层隐藏了大多数网络通信的复杂细节，比如丢包重发、按序发送、拥塞控制及避免、数据完整等等。采用TCP数据流可以确保发送的所有字节能够完整地被接收到，而且到达客户端的顺序也一样。也就是说，TCP专门为精确传送做了优化，但并未过多顾及时间。

#### 2.1 三次握手

所有TCP连接一开始都要经过三次握手。客户端与服务器在交换应用数据之前，必须就起始分组序列号，以及其他一些连接相关但细节达成一致，出于安全考虑，序列号有两端随机生成。

![三次握手](/img/web-performance-optimization/shake-hand.png)

- SYN
    
    客户端选择一个随机序列号x，并发送一个SYN分组，其中可能还包括其他TCP标志和选项。
- SYN ACK
    服务器给x加1，并选择自己的一个随机序列号y，追加自己的标志和选项，然后返回响应。
- ACK
    客户端给x和y加1并发送握手期间的最后一个ACK分组

三次握手完成后，客户端与服务器之间就可以通信了。客户端可以在发送ACK分组之后立即发送数据，而服务器必须等接收到ACK分组之后才能发送数据。这个启动通信的过程适用于所有TCP连接，因此对所有使用TCP的应用具有费城大的性能影响，因为每次传输应用数据之前，都必须经历一次完整的往返。

三次握手带来的延迟使得每创建一个新TCP连接都要付出很大代价。而这也决定了提高TCP应用性能的关键，在于想办法重用连接。

#### 2.2 拥塞预防及控制

##### 2.2.1 流量控制

流量控制是一种预防发送端过多向接收端发送数据的机制。否则，接收端可能因为忙碌、负载重或缓冲区既定而无法处理。为实现流量控制，TCP连接的每一方都要通告自己的接收窗口（rwnd），其中包含能够保存数据的缓冲区空间大小信息。

第一次建立连接时，两端都会使用自身系统的默认设置来发送rwnd。浏览网页通常主要是从服务器向客户端下载数据，因此客户端窗口更可能称为瓶颈。然而，如果是在上传图片或视频，即客户端向服务器传送大量数据时，服务器的接收窗口又可能成为制约因素。

不管怎样，如果其中一端跟不上数据传输，那它可以向发送端通告一个较小的窗口。如果窗口为零，则意味着必须由应用层先清空缓冲区，才能再接收剩余数据。这个过程贯穿于每个TCP连接的整个生命周期：每个ACK分组都会携带相应的最新rwnd值，以便两端动态调整数据流速，使之适应发送端和接收端的容量和处理能力。

##### 2.2.2 慢启动

尽管TCP有了流量控制机制，但网络拥塞崩溃仍然在1980年代中后期浮出水面。流量控制确实可以防止发送端向接收端发送过多数据，但却没有机制预防任何一端向潜在网络发送过多数据。换句话说，接收端和发送端在连接建立之初，谁也不知道可用带宽是多少，因此需要一个估算机制，然后还要根据网络中不断变化的条件而动态改变速度。

慢启动算法的设计思路就是根据交换数据来估算客户端于服务器之间的可用带宽。首先，服务器通过TCP连接初始化一个新的拥塞窗口（cwnd）变量，将其值设置为一个系统设定的保守值。

- 拥塞窗口大小（cwnd）

  发送端对客户端接收确认（ACK）之前可以发送数据量的限制。

新的TCP连接传输的最大数据量取rwnd和cwnd中的最小值，而服务器实际上可以向客户端发送4个TCP 段，然后就必须停下来等待确认。此后，每收到一个ACK，慢启动算法就会告诉服务器可以将它的cwnd窗口增加一个TCP段。每次收到ACK后，都可以发送两个新的分组。TCP连接的这个阶段通常被称为“指数增长”阶段。因为客户端和服务器都在向两者之间网络路径的有效带宽靠拢。
![拥塞控制和拥塞预防](/img/web-performance-optimization/cwnd.png)
为什么知道有个慢启动对我们构建浏览器应用这么重要呢？因为包括HTTP在内的很多应用层协议都运行在TCP之上，无论带宽多大，每个TCP连接都必须经过慢启动阶段。换句话说，我们不可能一上来就完全利用连接的最大带宽。

相反，我们要从一个相对较小的拥塞窗口开始，每次往返都令其翻倍（指数式增长）。而达到某个目标吞吐量所需的时间，就是客户端和服务器之间的往返时间和初始拥塞窗口大小的函数。
![cwnd大小达到 N 所需的时间](/img/web-performance-optimization/cwnd-time.jpg)
慢启动导致客户端于服务器之间经过几百ms才能达到接近最大速度的问题，对于大型流式下载服务的影响倒不显著，因为慢启动的时间可以分摊到整个传输周期内消化掉。

可是，对于很多HTTP连接，特别是一些短暂、突发的连接而言，常常会出现还没有达到最大窗口请求就被终止的情况。换句话说，很多web应用的性能经常受到服务器于客户端之间往返时间的制约。因为慢启动限制了可用的吞吐量，而这对于小文件传输非常不利。

##### 2.2.3 拥塞预防

拥塞预防算法把丢包作为网络拥塞的标志，即路径中某个连接或路由器已经拥堵了，以至于必须采取删包措施。因此，必须调整窗口大小，以避免造成更多的包丢失，从而保证网络畅通。

重置拥塞窗口后，拥塞预防机制按照自己的算法来增大窗口以尽量避免丢包。某个过程，有可能又有包丢失，于是这个过程再从头开始。

#### 2.3 带宽延迟积

TCP内置的拥塞控制和预防机制对性能还有另一个重要影响：发送端和接收端理想的窗口大小，一定会因往返时间及目标传输速率而变化。

因为发送端和接收端之间在途未确认的最大数据量，都必须停下来等待另一方ACK确认某些分组才能继续。需要等待的时间取决于往返时间。
+ BDP(Bandwidth-delay product, 带宽延迟积)
    
    数据链路的容量与其端到端延迟的乘积。这个结果就是任意时刻处于在途未确认状态的最大数据量。

发送端或接收端无论谁被迫频繁地停止等待之前的分组的ACK，都会造成数据缺口，从而必然限制连接的最大吞吐量。为解决这个问题，应该让窗口足够大，以保证任何一端都能在ACK返回前持续发送数据。只有传输不中断，才能保证最大吞吐量。而最优窗口大小取决于往返时间！无论实际或通告的带宽是多大，窗口过小都会限制连接的吞吐量。

#### 2.4 队首阻塞

TCP在不可靠的信道上实现了可靠的网络传输。基本的分组错误检测与纠正、按序交付、丢包重发，以及保证网络最高效率的流量控制、拥塞控制和预防机制，让TCP成为大多数网络应用中最常见的传输协议。

虽然TCP很流行，但它并不是唯一但选择，而且在某些情况下也不是最佳的选择，特别是按序交付和可靠交付有时候并不必要，反而会导致额外的延迟，对象能造成负面影响。因为每个TCP分组都会带着一个唯一的序列号被发出，而所有分组必须按顺序传送到接收端。如果中途有一个分组没能到达接收端，那么后续分组必须保存在接收端的TCP缓冲区，等待丢失的分组重发并到达接收端。这一切都发生在TCP层，应用程序对TCP重发和缓冲区中排队的分组一无所知，必须等待分组全部到达才能访问数据。在此之前，应用程序只能通过套接字读取数据时感觉到延迟交付。这种效应称为TCP的队首(HOL, Head of Line)阻塞。
![TCP队首阻塞](/img/web-performance-optimization/head-of-line.jpg)
队首阻塞造成的延迟可以让我们的应用程序不用关心分组重排和重组，从而让代码保持简洁。然而，代码简洁也是要付出代价的，那就是分组到达时间会存在无法预知的延迟变化。这个时间变化通常被称为抖动，也是影响应用程序性能的一个主要因素。

另外，有些应用程序可能并不需要可靠的交付或者不需要按序交付。比如，每个分组都是独立的消息，那么按序交付就没有任何必要。而且，如果每个消息都会覆盖之前的消息，那么可靠交付也同样没有必要了。可惜的是，TCP不支持这种情况，所有分组都必须按序交付。

无需按序交付数据或能够处理分组丢失的应用程序，以及对延迟或抖动要求很高的应用程序，最好选择UDP等协议。

#### 2.5 针对TCP的优化建议

TCP是一个自适应的、对所有网络节点一视同仁的、最大限制利用底层网络的协议。因此，优化TCP的最佳途径就是调整它感知当前网络状况的方式，根据它之上或之下的抽象层的类型和需求来改变它的行为。无线网络可能需要不同的拥塞算法，而某些应用程序可能需要自定义服务品质(QoS,Quality of Service)的含义，从而交付最佳的体验。

尽管每个算法和反馈机制的具体细节可能会继续发展，但核心原理以及它们但影响是不变的：
- TCP三次握手增加了整整一次往返时间
- TCP慢启动将被应用到每个新连接
- TCP流量及拥塞控制会影响所有连接的吞吐量
- TCP的吞吐量由当前拥塞窗口大小控制

大多数情况下，TCP的瓶颈都是延迟而非带宽。

##### 2.5.1 服务器配置调优

在着手调整TCP缓冲区、超时等数十个变量之前，最好先把主机操作系统升级到最新版本。TCP的最佳实践以及影响其性能的底层算法一直在与时俱进，而且大多数变化都只在最新内核中才有实现。一句话，让你的服务器跟上时代是优化发送端和接收端TCP栈的首要措施。
- 增大TCP的初始拥塞窗口
    
    加大起始拥塞窗口可以让TCP在第一次往返就传输较多数据，而随后的速度提升也会很明显。对于突发性的短暂连接，这也是特别关键的一个优化。
- 慢启动重启

    在连接空闲时禁用慢启动可以改善瞬时发送数据的长TCP连接的性能。
- 窗口缩放

    启用窗口缩放可以增大最大接受窗口大小，可以让高延迟的连接达到更好吞吐量。
- TCP快速打开

    在某些条件下，允许在第一个SYN分组中发送应用程序数据。TFO(TCP Fast Open)是一种新的优化选项，需要客户端和服务器共同支持。为此，首先要搞清楚你的应用程序是否可以利用这个特性。
以上几个设置再加上最新的内核，可以确保最佳性能：每个TCP连接都会具有较低的延迟和较高的吞吐量。

##### 2.5.2 应用程序行为调优

调优TCP性能可以让服务器和客户端之前达到最大吞吐量和最小延迟。而应用程序如何使用新的或已经建立的TCP连接同样也有很大的关系。
- 再快也快不过什么也不用发送，能少发就少发
- 我们不能让数据传输更快，但可以让它们传输的距离更短
- 重用TCP连接是提升性能的关键

当然，消除不必要的数据传输本身就是很大的优化。比如减少下载不必要的资源，或者通过压缩算法把要发送的比特数降到最低。然后，通过在不同地区部署服务器（比如使用CDN），把数据放到接近客户端的地方，可以减少网络往返的延迟，从而显著提升TCP性能。最后，尽可能重用已建立的TCP连接，把慢启动和其他拥塞控制机制的影响降到最低。

##### 2.2.6 性能检查清单

优化TCP性能的回报是丰厚的，无论什么应用，性能提升可以在与服务器的每个连接中体现出来。
- 把服务器内核升级到最新版本
- 确保cwnd大小为10
- 禁用空闲后的慢启动
- 确保启动窗口缩放
- 减少传输冗余数据
- 压缩要传输的数据
- 把服务器放到离用户最近的地方以减少往返时间
- 尽最大可能重用已经建立的TCP连接


### 第三章 UDP的构成
#### 3.1 无协议服务

UDP协议会用自己的分组结构封装用户消息，它只增加了4个字段：源端口、目标端口、分组长度和校验和。这样，当IP把分组送达目标主机时，该主机能够拆开UDP分组，根据目标端口找到目标应用程序，然后再把消息发送过去。仅此而已。

事实上，UDP数据报中的源端口和校验和字段都是可选的。IP分组的首部也有校验和，应用程序可以忽略UDP校验和。也就是说，所有错误检测和错误纠正工作都可以委托给上层的应用程序。说到底，UDP仅仅是在IP层之上通过嵌入应用程序的源端口和目标端口，提供了一个“应用程序多路复用”机制。
- 不保证消息交付

    不确认，不重传，无超时
- 不保证交付顺序
    
    不设置包序号，不重排，不会发生队首阻塞
- 不跟踪连接状态

    不必建立连接或重启状态机
- 不需要拥塞控制

    不内置客户端或网络反馈机制

